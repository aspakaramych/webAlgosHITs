{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-30T11:08:28.272484Z",
     "start_time": "2025-03-30T11:08:27.655625Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:09:13.283669Z",
     "start_time": "2025-03-30T11:09:11.705553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"oddrationale/mnist-in-csv\")\n",
    "print(\"Path to dataset files\", path)"
   ],
   "id": "7e7c565511ccdde2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgrig\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files C:\\Users\\vgrig\\.cache\\kagglehub\\datasets\\oddrationale\\mnist-in-csv\\versions\\2\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:10:17.070122Z",
     "start_time": "2025-03-30T11:10:11.729520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_csv = pd.read_csv(path + \"/mnist_train.csv\")\n",
    "test_csv = pd.read_csv(path + \"/mnist_test.csv\")\n",
    "train_2_csv = pd.read_csv(\"./data/train.csv\")\n",
    "train_csv"
   ],
   "id": "5c654ce416471062",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0          5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1          0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2          4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "59995      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59997      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59998      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59999      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0          0      0      0      0      0      0      0      0  \n",
       "1          0      0      0      0      0      0      0      0  \n",
       "2          0      0      0      0      0      0      0      0  \n",
       "3          0      0      0      0      0      0      0      0  \n",
       "4          0      0      0      0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "59995      0      0      0      0      0      0      0      0  \n",
       "59996      0      0      0      0      0      0      0      0  \n",
       "59997      0      0      0      0      0      0      0      0  \n",
       "59998      0      0      0      0      0      0      0      0  \n",
       "59999      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:19:43.799970Z",
     "start_time": "2025-03-30T11:19:42.457944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train = np.array(train_csv.iloc[:, 1:].values)\n",
    "x_2_train = np.array(train_2_csv.iloc[:, 1:].values)\n",
    "y_train = np.array(train_csv.iloc[:, 0].values)\n",
    "y_2_train = np.array(train_2_csv.iloc[:, 0].values)\n",
    "x_train = np.array(np.concatenate([x_train.data, x_2_train.data], axis=0))\n",
    "y_train = np.array(np.concatenate([y_train.data, y_2_train.data], axis=0))\n",
    "print(x_train.shape)\n",
    "x_train = x_train / 255.0\n",
    "x_test = np.array(test_csv.iloc[:, 1:].values)\n",
    "y_test = np.array(test_csv.iloc[:, 0].values)\n",
    "x_test = x_test / 255.0\n",
    "print(x_test.shape)"
   ],
   "id": "5f604826a91b4146",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:19:44.391488Z",
     "start_time": "2025-03-30T11:19:44.379754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_one_hot(y, num_classes):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "\n",
    "y_train = to_one_hot(y_train, 10)\n",
    "y_test = to_one_hot(y_test, 10)"
   ],
   "id": "8dd12b0de350a95",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:19:45.201417Z",
     "start_time": "2025-03-30T11:19:45.191674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weights = np.random.randn(in_features, out_features) * np.sqrt(2 / in_features)\n",
    "        self.input = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return np.dot(x, self.weights)\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        grad_input = np.dot(grad_output, self.weights.T)\n",
    "        grad_weights = np.dot(self.input.T, grad_output)\n",
    "        self.weights -= learning_rate * grad_weights\n",
    "        return grad_input"
   ],
   "id": "cb26b8a134d0cd7b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:19:45.788190Z",
     "start_time": "2025-03-30T11:19:45.776514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x > 0).astype(float)\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.mask"
   ],
   "id": "60ca03cb6e10518f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:19:46.245339Z",
     "start_time": "2025-03-30T11:19:46.237873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, is_training=True):\n",
    "        if is_training:\n",
    "            self.mask = np.random.binomial(1, 1 - self.dropout_rate, size=x.shape)\n",
    "            return x * self.mask / (1 - self.dropout_rate)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.mask / (1 - self.dropout_rate)"
   ],
   "id": "9f1f1e124dfd372e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:19:46.684384Z",
     "start_time": "2025-03-30T11:19:46.674633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        self.output = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_input = self.output * (grad_output - np.sum(self.output * grad_output, axis=1, keepdims=True))\n",
    "        return grad_input"
   ],
   "id": "9d045bc1e6d4ce2d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:19:47.091238Z",
     "start_time": "2025-03-30T11:19:47.081656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "class Sequential:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, x, is_training=True):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, is_training)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        for layer in reversed(self.layers):\n",
    "            if hasattr(layer, 'backward'):\n",
    "                if 'learning_rate' in inspect.signature(layer.backward).parameters:\n",
    "                    grad_output = layer.backward(grad_output, learning_rate)\n",
    "                else:\n",
    "                    grad_output = layer.backward(grad_output)"
   ],
   "id": "3b5bd1330a0dde2",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:19:47.553884Z",
     "start_time": "2025-03-30T11:19:47.547003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    loss = -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
    "    grad = -(y_true / y_pred) / y_true.shape[0]\n",
    "    return loss, grad"
   ],
   "id": "8721573cecb13bcd",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:21:14.811825Z",
     "start_time": "2025-03-30T11:19:48.250013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Linear(in_features=784, out_features=128))\n",
    "model.add(ReLU())\n",
    "model.add(Dropout(dropout_rate=0.5))\n",
    "model.add(Linear(in_features=128, out_features=num_classes))\n",
    "model.add(Softmax())\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    correct_cnt = 0\n",
    "    for batch_start in range(0, len(x_train), batch_size):\n",
    "        batch_end = batch_start + batch_size\n",
    "        x_batch = x_train[batch_start:batch_end]\n",
    "        y_batch = y_train[batch_start:batch_end]\n",
    "\n",
    "        output = model.forward(x_batch, is_training=True)\n",
    "        loss, grad_loss = cross_entropy_loss(output, y_batch)\n",
    "        total_loss += loss\n",
    "\n",
    "        model.backward(grad_loss, learning_rate)\n",
    "        correct_cnt += np.sum(np.argmax(output, axis=1) == np.argmax(y_batch, axis=1))\n",
    "\n",
    "    test_output = model.forward(x_test, is_training=False)\n",
    "    test_accuracy = np.mean(np.argmax(test_output, axis=1) == y_test_labels)\n",
    "    train_accuracy = correct_cnt / len(x_train)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}, Train Acc: {train_accuracy:.4f}, Test Acc: {test_accuracy:.4f}\")"
   ],
   "id": "5c3eeda596778a41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2960.3406, Train Acc: 0.3938, Test Acc: 0.7407\n",
      "Epoch 2, Loss: 2002.9303, Train Acc: 0.6361, Test Acc: 0.8150\n",
      "Epoch 3, Loss: 1583.5418, Train Acc: 0.7073, Test Acc: 0.8435\n",
      "Epoch 4, Loss: 1357.0007, Train Acc: 0.7470, Test Acc: 0.8583\n",
      "Epoch 5, Loss: 1214.0393, Train Acc: 0.7733, Test Acc: 0.8692\n",
      "Epoch 6, Loss: 1116.9885, Train Acc: 0.7920, Test Acc: 0.8785\n",
      "Epoch 7, Loss: 1047.0269, Train Acc: 0.8061, Test Acc: 0.8834\n",
      "Epoch 8, Loss: 990.8304, Train Acc: 0.8176, Test Acc: 0.8878\n",
      "Epoch 9, Loss: 945.4282, Train Acc: 0.8251, Test Acc: 0.8918\n",
      "Epoch 10, Loss: 904.3111, Train Acc: 0.8338, Test Acc: 0.8941\n",
      "Epoch 11, Loss: 875.1268, Train Acc: 0.8388, Test Acc: 0.8975\n",
      "Epoch 12, Loss: 846.5188, Train Acc: 0.8433, Test Acc: 0.9013\n",
      "Epoch 13, Loss: 820.7044, Train Acc: 0.8500, Test Acc: 0.9033\n",
      "Epoch 14, Loss: 800.6268, Train Acc: 0.8528, Test Acc: 0.9048\n",
      "Epoch 15, Loss: 781.5819, Train Acc: 0.8564, Test Acc: 0.9066\n",
      "Epoch 16, Loss: 761.1379, Train Acc: 0.8605, Test Acc: 0.9080\n",
      "Epoch 17, Loss: 748.5518, Train Acc: 0.8633, Test Acc: 0.9096\n",
      "Epoch 18, Loss: 730.6392, Train Acc: 0.8667, Test Acc: 0.9117\n",
      "Epoch 19, Loss: 721.6966, Train Acc: 0.8692, Test Acc: 0.9132\n",
      "Epoch 20, Loss: 708.8203, Train Acc: 0.8704, Test Acc: 0.9148\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T11:22:22.292587Z",
     "start_time": "2025-03-30T11:22:21.932519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "weights_data = {}\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if isinstance(layer, Linear):\n",
    "        weights_data[f\"layer_{i}\"] = {\n",
    "            \"weights\": layer.weights.tolist(),\n",
    "        }\n",
    "\n",
    "with open(\"./weights/weights.json\", \"w\") as json_file:\n",
    "    json.dump(weights_data, json_file, indent=4)\n",
    "\n",
    "print(\"Веса успешно сохранены в файл\")"
   ],
   "id": "74b7c9ca693ed6fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса успешно сохранены в файл\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6ccab859ef517338"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
