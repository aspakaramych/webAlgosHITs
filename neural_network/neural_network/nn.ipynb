{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-30T15:09:07.359499Z",
     "start_time": "2025-03-30T15:09:06.696715Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:09:09.681006Z",
     "start_time": "2025-03-30T15:09:08.258503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"oddrationale/mnist-in-csv\")"
   ],
   "id": "7e7c565511ccdde2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgrig\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:09:15.420777Z",
     "start_time": "2025-03-30T15:09:10.228633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_csv = pd.read_csv(path + \"/mnist_train.csv\")\n",
    "test_csv = pd.read_csv(path + \"/mnist_test.csv\")\n",
    "train_2_csv = pd.read_csv(\"./data/train.csv\")\n",
    "train_csv"
   ],
   "id": "5c654ce416471062",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0          5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1          0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2          4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "59995      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59997      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59998      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59999      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0          0      0      0      0      0      0      0      0  \n",
       "1          0      0      0      0      0      0      0      0  \n",
       "2          0      0      0      0      0      0      0      0  \n",
       "3          0      0      0      0      0      0      0      0  \n",
       "4          0      0      0      0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "59995      0      0      0      0      0      0      0      0  \n",
       "59996      0      0      0      0      0      0      0      0  \n",
       "59997      0      0      0      0      0      0      0      0  \n",
       "59998      0      0      0      0      0      0      0      0  \n",
       "59999      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:09:17.478651Z",
     "start_time": "2025-03-30T15:09:15.883969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train = np.array(train_csv.iloc[:, 1:].values)\n",
    "x_2_train = np.array(train_2_csv.iloc[:, 1:].values)\n",
    "y_train = np.array(train_csv.iloc[:, 0].values)\n",
    "y_2_train = np.array(train_2_csv.iloc[:, 0].values)\n",
    "x_train = np.array(np.concatenate([x_train.data, x_2_train.data], axis=0))\n",
    "y_train = np.array(np.concatenate([y_train.data, y_2_train.data], axis=0))\n",
    "print(x_train.shape)\n",
    "x_train = x_train / 255.0\n",
    "x_test = np.array(test_csv.iloc[:, 1:].values)\n",
    "y_test = np.array(test_csv.iloc[:, 0].values)\n",
    "x_test = x_test / 255.0\n",
    "print(x_test.shape)"
   ],
   "id": "5f604826a91b4146",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:09:21.076546Z",
     "start_time": "2025-03-30T15:09:21.065708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_one_hot(y, num_classes):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "\n",
    "y_train = to_one_hot(y_train, 10)\n",
    "y_test = to_one_hot(y_test, 10)"
   ],
   "id": "8dd12b0de350a95",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:09:22.706373Z",
     "start_time": "2025-03-30T15:09:22.698550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weights = np.random.randn(in_features, out_features) * np.sqrt(2 / in_features)\n",
    "        self.input = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return np.dot(x, self.weights)\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        grad_input = np.dot(grad_output, self.weights.T)\n",
    "        grad_weights = np.dot(self.input.T, grad_output)\n",
    "        self.weights -= learning_rate * grad_weights\n",
    "        return grad_input"
   ],
   "id": "cb26b8a134d0cd7b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:09:23.108117Z",
     "start_time": "2025-03-30T15:09:23.100344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x > 0).astype(float)\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.mask"
   ],
   "id": "60ca03cb6e10518f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:09:23.469729Z",
     "start_time": "2025-03-30T15:09:23.460083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, is_training=True):\n",
    "        if is_training:\n",
    "            self.mask = np.random.binomial(1, 1 - self.dropout_rate, size=x.shape)\n",
    "            return x * self.mask / (1 - self.dropout_rate)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.mask / (1 - self.dropout_rate)"
   ],
   "id": "9f1f1e124dfd372e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:09:23.803031Z",
     "start_time": "2025-03-30T15:09:23.793639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        self.output = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_input = self.output * (grad_output - np.sum(self.output * grad_output, axis=1, keepdims=True))\n",
    "        return grad_input"
   ],
   "id": "9d045bc1e6d4ce2d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:09:24.143414Z",
     "start_time": "2025-03-30T15:09:24.135018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "class Sequential:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, x, is_training=True):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, is_training)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        for layer in reversed(self.layers):\n",
    "            if hasattr(layer, 'backward'):\n",
    "                if 'learning_rate' in inspect.signature(layer.backward).parameters:\n",
    "                    grad_output = layer.backward(grad_output, learning_rate)\n",
    "                else:\n",
    "                    grad_output = layer.backward(grad_output)"
   ],
   "id": "3b5bd1330a0dde2",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:09:25.420758Z",
     "start_time": "2025-03-30T15:09:25.412628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    loss = -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
    "    grad = -(y_true / y_pred) / y_true.shape[0]\n",
    "    return loss, grad"
   ],
   "id": "8721573cecb13bcd",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:10:51.860053Z",
     "start_time": "2025-03-30T15:09:26.273890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Linear(in_features=784, out_features=256))\n",
    "model.add(ReLU())\n",
    "model.add(Dropout(dropout_rate=0.5))\n",
    "model.add(Linear(in_features=256, out_features=num_classes))\n",
    "model.add(Softmax())\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    correct_cnt = 0\n",
    "    for batch_start in range(0, len(x_train), batch_size):\n",
    "        batch_end = batch_start + batch_size\n",
    "        x_batch = x_train[batch_start:batch_end]\n",
    "        y_batch = y_train[batch_start:batch_end]\n",
    "\n",
    "        output = model.forward(x_batch, is_training=True)\n",
    "        loss, grad_loss = cross_entropy_loss(output, y_batch)\n",
    "        total_loss += loss\n",
    "\n",
    "        model.backward(grad_loss, learning_rate)\n",
    "        correct_cnt += np.sum(np.argmax(output, axis=1) == np.argmax(y_batch, axis=1))\n",
    "\n",
    "    test_output = model.forward(x_test, is_training=False)\n",
    "    test_accuracy = np.mean(np.argmax(test_output, axis=1) == y_test_labels)\n",
    "    train_accuracy = correct_cnt / len(x_train)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}, Train Acc: {train_accuracy:.4f}, Test Acc: {test_accuracy:.4f}\")"
   ],
   "id": "5c3eeda596778a41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1675.7185, Train Acc: 0.2538, Test Acc: 0.6333\n",
      "Epoch 2, Loss: 1278.3874, Train Acc: 0.5259, Test Acc: 0.7543\n",
      "Epoch 3, Loss: 1032.0209, Train Acc: 0.6401, Test Acc: 0.7966\n",
      "Epoch 4, Loss: 873.4849, Train Acc: 0.6952, Test Acc: 0.8243\n",
      "Epoch 5, Loss: 768.5697, Train Acc: 0.7273, Test Acc: 0.8399\n",
      "Epoch 6, Loss: 696.0287, Train Acc: 0.7526, Test Acc: 0.8510\n",
      "Epoch 7, Loss: 641.5478, Train Acc: 0.7688, Test Acc: 0.8595\n",
      "Epoch 8, Loss: 600.1155, Train Acc: 0.7818, Test Acc: 0.8677\n",
      "Epoch 9, Loss: 567.9381, Train Acc: 0.7940, Test Acc: 0.8744\n",
      "Epoch 10, Loss: 541.3075, Train Acc: 0.8025, Test Acc: 0.8774\n",
      "Epoch 11, Loss: 517.1367, Train Acc: 0.8120, Test Acc: 0.8813\n",
      "Epoch 12, Loss: 497.6601, Train Acc: 0.8172, Test Acc: 0.8848\n",
      "Epoch 13, Loss: 481.9217, Train Acc: 0.8242, Test Acc: 0.8880\n",
      "Epoch 14, Loss: 468.2450, Train Acc: 0.8286, Test Acc: 0.8912\n",
      "Epoch 15, Loss: 454.6172, Train Acc: 0.8339, Test Acc: 0.8935\n",
      "Epoch 16, Loss: 441.4305, Train Acc: 0.8383, Test Acc: 0.8950\n",
      "Epoch 17, Loss: 432.1474, Train Acc: 0.8424, Test Acc: 0.8968\n",
      "Epoch 18, Loss: 423.7181, Train Acc: 0.8454, Test Acc: 0.8983\n",
      "Epoch 19, Loss: 414.4020, Train Acc: 0.8486, Test Acc: 0.9004\n",
      "Epoch 20, Loss: 405.8723, Train Acc: 0.8508, Test Acc: 0.9006\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:10:56.136824Z",
     "start_time": "2025-03-30T15:10:55.534288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "weights_data = {}\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if isinstance(layer, Linear):\n",
    "        weights_data[f\"layer_{i}\"] = {\n",
    "            \"weights\": layer.weights.T.tolist(),\n",
    "        }\n",
    "\n",
    "with open(\"./weights/weights.json\", \"w\") as json_file:\n",
    "    json.dump(weights_data, json_file, indent=4)\n",
    "\n",
    "print(\"Веса успешно сохранены в файл\")"
   ],
   "id": "74b7c9ca693ed6fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса успешно сохранены в файл\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T12:24:32.167722Z",
     "start_time": "2025-03-30T12:24:32.144327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(28, 28)):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = image.resize(target_size)\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    if np.mean(image_array) > 127:\n",
    "        image_array = 255 - image_array\n",
    "\n",
    "    image_array = image_array / 255.0\n",
    "\n",
    "    image_array = image_array.flatten().reshape(1, -1)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def predict_image(model, image_path):\n",
    "    processed_image = load_and_preprocess_image(image_path)\n",
    "    output = model.forward(processed_image, is_training=False)\n",
    "\n",
    "    probabilities = np.exp(output)\n",
    "\n",
    "    predicted_class = np.argmax(probabilities, axis=1)[0]\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "image_path = r\"C:\\Users\\vgrig\\Desktop\\Untitled.png\"\n",
    "\n",
    "predicted_class, probabilities = predict_image(model, image_path)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Probabilities: {probabilities}\")"
   ],
   "id": "6ccab859ef517338",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2\n",
      "Probabilities: [[1.00332147 1.00900844 2.04195683 1.08633619 1.00684934 1.02201877\n",
      "  1.13067672 1.02854544 1.00884746 1.00262372]]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "37191e0af618a72a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
