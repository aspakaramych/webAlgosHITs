{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-06T04:55:48.548713Z",
     "start_time": "2025-04-06T04:55:47.370280Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import weight_dict"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T04:55:56.312428Z",
     "start_time": "2025-04-06T04:55:54.375190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"oddrationale/mnist-in-csv\")"
   ],
   "id": "7e7c565511ccdde2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgrig\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.11).\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T05:07:48.115584Z",
     "start_time": "2025-04-06T05:07:40.764056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_csv = pd.read_csv(path + \"/mnist_train.csv\")\n",
    "test_csv = pd.read_csv(path + \"/mnist_test.csv\")\n",
    "train_2_csv = pd.read_csv(\"./data/train.csv\")\n",
    "train_csv"
   ],
   "id": "5c654ce416471062",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0          5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1          0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2          4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "59995      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59997      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59998      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59999      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0          0      0      0      0      0      0      0      0  \n",
       "1          0      0      0      0      0      0      0      0  \n",
       "2          0      0      0      0      0      0      0      0  \n",
       "3          0      0      0      0      0      0      0      0  \n",
       "4          0      0      0      0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "59995      0      0      0      0      0      0      0      0  \n",
       "59996      0      0      0      0      0      0      0      0  \n",
       "59997      0      0      0      0      0      0      0      0  \n",
       "59998      0      0      0      0      0      0      0      0  \n",
       "59999      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T05:07:50.535184Z",
     "start_time": "2025-04-06T05:07:48.812502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train = np.array(train_csv.iloc[:, 1:].values)\n",
    "x_2_train = np.array(train_2_csv.iloc[:, 1:].values)\n",
    "y_train = np.array(train_csv.iloc[:, 0].values)\n",
    "y_2_train = np.array(train_2_csv.iloc[:, 0].values)\n",
    "x_train = np.array(np.concatenate([x_train.data, x_2_train.data], axis=0))\n",
    "y_train = np.array(np.concatenate([y_train.data, y_2_train.data], axis=0))\n",
    "print(x_train.shape)\n",
    "x_train = x_train / 255.0\n",
    "x_test = np.array(test_csv.iloc[:, 1:].values)\n",
    "y_test = np.array(test_csv.iloc[:, 0].values)\n",
    "x_test = x_test / 255.0\n",
    "print(x_test.shape)"
   ],
   "id": "5f604826a91b4146",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T05:07:53.853201Z",
     "start_time": "2025-04-06T05:07:53.838068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_one_hot(y, num_classes):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "\n",
    "y_train = to_one_hot(y_train, 10)\n",
    "y_test = to_one_hot(y_test, 10)"
   ],
   "id": "8dd12b0de350a95",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T05:07:54.711313Z",
     "start_time": "2025-04-06T05:07:54.668194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "class Linear:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weights = np.random.randn(in_features, out_features) * np.sqrt(2 / in_features)\n",
    "        self.bias = np.zeros((1, out_features))\n",
    "        self.input = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return np.dot(x, self.weights) + self.bias\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        grad_input = np.dot(grad_output, self.weights.T)\n",
    "        grad_weights = np.dot(self.input.T, grad_output)\n",
    "        grad_bias = np.sum(grad_output, axis=0, keepdims=True)\n",
    "        self.weights -= learning_rate * grad_weights\n",
    "        self.bias -= learning_rate * grad_bias\n",
    "        return grad_input"
   ],
   "id": "cb26b8a134d0cd7b",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T05:07:55.470314Z",
     "start_time": "2025-04-06T05:07:55.465227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x > 0).astype(float)\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.mask"
   ],
   "id": "60ca03cb6e10518f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T05:07:55.893336Z",
     "start_time": "2025-04-06T05:07:55.887835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.output = np.tanh(x)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return (1 - self.output ** 2) * grad_output"
   ],
   "id": "16669880b1c3177a",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T05:07:56.333821Z",
     "start_time": "2025-04-06T05:07:56.323888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, is_training=True):\n",
    "        if is_training:\n",
    "            self.mask = np.random.binomial(1, 1 - self.dropout_rate, size=x.shape)\n",
    "            return x * self.mask / (1 - self.dropout_rate)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.mask / (1 - self.dropout_rate)"
   ],
   "id": "9f1f1e124dfd372e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T05:07:56.769664Z",
     "start_time": "2025-04-06T05:07:56.757214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        self.output = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_input = self.output * (grad_output - np.sum(self.output * grad_output, axis=1, keepdims=True))\n",
    "        return grad_input"
   ],
   "id": "9d045bc1e6d4ce2d",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T05:07:58.766343Z",
     "start_time": "2025-04-06T05:07:58.750567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "class Sequential:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, x, is_training=True):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, is_training)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        for layer in reversed(self.layers):\n",
    "            if hasattr(layer, 'backward'):\n",
    "                if 'learning_rate' in inspect.signature(layer.backward).parameters:\n",
    "                    grad_output = layer.backward(grad_output, learning_rate)\n",
    "                else:\n",
    "                    grad_output = layer.backward(grad_output)"
   ],
   "id": "3b5bd1330a0dde2",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T05:07:59.676177Z",
     "start_time": "2025-04-06T05:07:59.670249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    loss = -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
    "    grad = (y_pred - y_true) / y_true.shape[0]\n",
    "    return loss, grad"
   ],
   "id": "8721573cecb13bcd",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T08:15:30.309029Z",
     "start_time": "2025-04-06T06:46:24.487708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Linear(in_features=784, out_features=512))\n",
    "model.add(Tanh())\n",
    "model.add(Dropout(dropout_rate=0.5))\n",
    "model.add(Linear(in_features=512, out_features=256))\n",
    "model.add(Tanh())\n",
    "model.add(Linear(in_features=256, out_features=10))\n",
    "model.add(Softmax())\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    correct_cnt = 0\n",
    "    for batch_start in range(0, len(x_train), batch_size):\n",
    "        batch_end = batch_start + batch_size\n",
    "        x_batch = x_train[batch_start:batch_end]\n",
    "        y_batch = y_train[batch_start:batch_end]\n",
    "\n",
    "        output = model.forward(x_batch, is_training=True)\n",
    "        loss, grad_loss = cross_entropy_loss(output, y_batch)\n",
    "        total_loss += loss\n",
    "\n",
    "        model.backward(grad_loss, learning_rate)\n",
    "        correct_cnt += np.sum(np.argmax(output, axis=1) == np.argmax(y_batch, axis=1))\n",
    "\n",
    "    test_output = model.forward(x_test, is_training=False)\n",
    "    test_accuracy = np.mean(np.argmax(test_output, axis=1) == y_test_labels)\n",
    "    train_accuracy = correct_cnt / len(x_train)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}, Train Acc: {train_accuracy:.4f}, Test Acc: {test_accuracy:.4f}\")"
   ],
   "id": "5c3eeda596778a41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 35842.7205, Train Acc: 0.9032, Test Acc: 0.9490\n",
      "Epoch 2, Loss: 21309.1511, Train Acc: 0.9451, Test Acc: 0.9625\n",
      "Epoch 3, Loss: 16320.2255, Train Acc: 0.9576, Test Acc: 0.9713\n",
      "Epoch 4, Loss: 13675.9767, Train Acc: 0.9643, Test Acc: 0.9762\n",
      "Epoch 5, Loss: 11742.5845, Train Acc: 0.9689, Test Acc: 0.9764\n",
      "Epoch 6, Loss: 10686.1380, Train Acc: 0.9713, Test Acc: 0.9798\n",
      "Epoch 7, Loss: 9629.2216, Train Acc: 0.9743, Test Acc: 0.9818\n",
      "Epoch 8, Loss: 8940.0330, Train Acc: 0.9767, Test Acc: 0.9820\n",
      "Epoch 9, Loss: 8530.1432, Train Acc: 0.9779, Test Acc: 0.9829\n",
      "Epoch 10, Loss: 7894.7763, Train Acc: 0.9796, Test Acc: 0.9849\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T08:17:03.099834Z",
     "start_time": "2025-04-06T08:17:01.290619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "weights_data = {\n",
    "    \"weight_1\": {\n",
    "        \"weight\": model.layers[0].weights.tolist(),\n",
    "        \"bias\": model.layers[0].bias.tolist()\n",
    "    },\n",
    "    \"weight_2\":{\n",
    "        \"weight\": model.layers[3].weights.tolist(),\n",
    "        \"bias\": model.layers[3].bias.tolist()\n",
    "    },\n",
    "    \"weight_3\": {\n",
    "        \"weight\": model.layers[5].weights.tolist(),\n",
    "        \"bias\": model.layers[5].bias.tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"../backend/app/weights/weights.json\", 'w') as f:\n",
    "    json.dump(weights_data, f, indent=4)\n",
    "\n",
    "print(\"Веса успешно сохранены в файл\")"
   ],
   "id": "74b7c9ca693ed6fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса успешно сохранены в файл\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T05:16:45.768931Z",
     "start_time": "2025-04-06T05:16:45.754403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(28, 28)):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = image.resize(target_size)\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    if np.mean(image_array) > 127:\n",
    "        image_array = 255 - image_array\n",
    "\n",
    "    image_array = image_array / 255.0\n",
    "\n",
    "    image_array = image_array.flatten().reshape(1, -1)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "\n",
    "def predict_image(model, image_path):\n",
    "    processed_image = load_and_preprocess_image(image_path)\n",
    "    output = model.forward(processed_image, is_training=False)\n",
    "\n",
    "    probabilities = np.exp(output)\n",
    "\n",
    "    predicted_class = np.argmax(probabilities, axis=1)[0]\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "\n",
    "image_path = r\"C:\\Users\\vgrig\\Desktop\\Untitled.png\"\n",
    "\n",
    "predicted_class, probabilities = predict_image(model, image_path)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Probabilities: {probabilities}\")"
   ],
   "id": "6ccab859ef517338",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n",
      "Probabilities: [[1.05299529 1.30401587 1.0440659  1.05355725 1.0539827  1.09212795\n",
      "  1.07291014 1.10848117 1.12234448 1.17131655]]\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "603664dd07e5b0be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
